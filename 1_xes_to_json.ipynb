{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfda6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import hashlib\n",
    "from collections import OrderedDict # added for ordered dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8b7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILENAME = \"13small.xes\"\n",
    "OUTPUT_FILENAME = INPUT_FILENAME.replace(\".xes\", \".json\")\n",
    "# optional user-provided classifier\n",
    "# keys separated by whitespace, e.g. \"concept:name lifecycle:transition\"\n",
    "CLASSIFIER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75c494d-0880-4855-a56c-2b32fb9d2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file content and compute its hash\n",
    "with open(INPUT_FILENAME) as f:\n",
    "    log_string = \"\".join(f.readlines())\n",
    "log_hash = hash(log_string)\n",
    "del log_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a0c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "objects = []\n",
    "event_object = []\n",
    "object_object = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15a6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_objects = {}\n",
    "#existing_events = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78620658",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(INPUT_FILENAME)\n",
    "root = tree.getroot()\n",
    "#TODO: check  in classifier if there is only concept name or lifecycle transition as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "772952d1-7c5e-440f-8f1a-4179297f0328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concept:name lifecycle:transition'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.findall('.//{http://www.xes-standard.org/}classifier')[0].get('keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269d9def-2ef3-4497-a762-04ded4857044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first classifier\n",
    "classifiers = root.findall('.//{http://www.xes-standard.org/}classifier')\n",
    "if CLASSIFIER:\n",
    "    # give the user the opportunity to specify classifier\n",
    "    classifier = CLASSIFIER\n",
    "elif classifiers:\n",
    "    # or use the first classifier in the log\n",
    "    classifier = classifiers[0].get('keys')   \n",
    "else:\n",
    "    # or fall back to concept:name and lifecycle:transition if no other information is provided\n",
    "    classifier = \"concept:name lifecycle:transition\"\n",
    "#classifier = CLASSIFIER if CLASSIFIER is not None else classifiers[0].get('keys')\n",
    "classifier = tuple(classifier.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3733721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id_counter = 1\n",
    "object_id_counter = 1\n",
    "case_id_counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbff3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "    case_attributes = [child for child in case.iter() if child.tag != '{http://www.xes-standard.org/}event']\n",
    "    xes_case_id = None\n",
    "    # check if case ID is present in the XES file\n",
    "    for attr in case_attributes:\n",
    "        if attr.get('key') == 'concept:name':\n",
    "            xes_case_id = attr.get('value')\n",
    "            break\n",
    "    # create a case object REGARDLESS of whether the case has an ID\n",
    "        # case ID depending on position, XES case ID (if present) and log hash\n",
    "    case_id = f\"case_{case_id_counter}_{xes_case_id}_{log_hash}\" if xes_case_id else f\"case_{case_id_counter}_{log_hash}\"\n",
    "    case_id_counter += 1\n",
    "    # append \"o_\" to the beginning of hashed case ID to prevent hashes starting from a number\n",
    "    # \"o_\" stands for object\n",
    "    # TODO: should we replace it with \"c_\" for case?\n",
    "    case_id_hashed = f\"o_{hashlib.sha1(case_id.encode()).hexdigest()}\"\n",
    "    objects.append({\"id\": case_id_hashed, \"object_type\": \"case\", \"attributes\": [{\"object_attribute_name\": \"concept:name\", \"object_attribute_value\": case_id}]})\n",
    "    \n",
    "    for attr in case_attributes:\n",
    "        if attr.get('key') != 'concept:name':\n",
    "            # add object\n",
    "            object_type = attr.get('key')\n",
    "            object_value = attr.get('value')\n",
    "            object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "             #generate a SHA-1 hash of the object key\n",
    "            if object_key not in existing_objects:\n",
    "                # append \"o_\" to the beginning of hashed object ID to prevent hashes starting from a number\n",
    "                object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                objects.append({\"id\": object_hash, \"object_type\": object_type, \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]})\n",
    "            else:\n",
    "                existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "            object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "            object_object.append({\"from\": case_id_hashed, \"to\": object_id_hashed, \"object_relation_type\": \"case_object\"})\n",
    "       \n",
    "    for event in [child for child in case.iter() if child.tag == '{http://www.xes-standard.org/}event']:\n",
    "        # identify event by its position\n",
    "        event_id = f\"event_{event_id_counter}_{log_hash}\"\n",
    "        event_id_counter += 1\n",
    "        # append \"e_\" to the beginning of hashed event ID to prevent hashes starting from a number\n",
    "        event_id_hashed = f\"e_{hashlib.sha1(event_id.encode()).hexdigest()}\"\n",
    "        event_time_element = event.find('.//{http://www.xes-standard.org/}date')\n",
    "        event_time_iso8601 = None\n",
    "\n",
    "        if event_time_element is not None:\n",
    "            event_time = event_time_element.attrib.get('value')\n",
    "            # event time to ISO 8601 format \n",
    "            if event_time:\n",
    "                event_time_iso8601 = event_time.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "        # take all attributes from classifier\n",
    "        event_classifier = OrderedDict.fromkeys(classifier)\n",
    "\n",
    "        event_attributes = [attr for attr in event.iter()]\n",
    "        for attr in event_attributes:\n",
    "            # fill in event_classifier with values present in the event\n",
    "            if attr.get('key') in event_classifier:\n",
    "                event_classifier[attr.get('key')] = attr.get('value')\n",
    "            # if attr.get('key') == 'concept:name':\n",
    "            #     concept_name = attr.get('value')\n",
    "            # elif attr.get('key') == 'lifecycle:transition':\n",
    "            #     lifecycle_transition = attr.get('value')\n",
    "        \n",
    "        # order of attribute values is preserved for all events\n",
    "        # skip None values, i.e. attributes not present in the event\n",
    "        event_type = \" \".join([v for v in event_classifier.values() if v is not None])\n",
    "        \n",
    "        # add the event\n",
    "        # only add the attributes that are present\n",
    "        events.append({\"id\": event_id_hashed, \"time\": event_time_iso8601, \"event_type\": event_type, \n",
    "                       \"attributes\":[{\"event_attribute_name\": k, \"event_attribute_value\": v} for k,v in event_classifier.items() if v is not None]})\n",
    "            \n",
    "        # add event_object relation to the case\n",
    "        event_object.append({\"eventID\": event_id_hashed, \"objectID\": case_id_hashed, \"qualifier\": \"case_event\"})\n",
    "\n",
    "            \n",
    "        # loop to Iterate through attributes of the event\n",
    "        for attr in event_attributes:\n",
    "            # only attributes that are not in the classifier and not timestamp are converted to objects\n",
    "            # timestamp is also not an attribute\n",
    "            #if attr.get('key') != 'concept:name' and attr.get('key') != 'lifecycle:transition' and attr.get('key') != 'time:timestamp':\n",
    "            if attr.get('key') not in event_classifier and attr.get('key') != 'time:timestamp':\n",
    "                # object already exists in objects list? if yes then take its id as an object_id\n",
    "                object_type = attr.get('key')\n",
    "                object_value = attr.get('value')\n",
    "                object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "                 #generate a SHA-1 hash of the object key\n",
    "                if object_key not in existing_objects:\n",
    "                    object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                    existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                    objects.append({\"id\": object_hash, \"object_type\": object_type, \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]})\n",
    "                else:\n",
    "                    existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "\n",
    "                event_object.append({\"eventID\": event_id_hashed, \"objectID\": object_id_hashed, \"qualifier\": \"event_object\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "258170ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(object_object) < 1:\n",
    "    # if this part is empty, add an empty entry for demonstrative purposes\n",
    "    object_object.append({\"from\": \"\", \"to\": \"\", \"object_relation_type\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6943bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {\n",
    "    \"events\": events,\n",
    "    \"objects\": objects,\n",
    "    \"event_object\": event_object,\n",
    "    \"object_object\": object_object\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf102863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to 13small.json\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_FILENAME, 'w') as json_file:\n",
    "    json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Output saved to {OUTPUT_FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e677282f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BPIC15_1.xes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 146\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_file \u001b[38;5;129;01min\u001b[39;00m INPUT_FILES:\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mprocess_file\u001b[0;34m(input_filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m input_filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Read the file content and compute its hash\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_filename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     log_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(f\u001b[38;5;241m.\u001b[39mreadlines())\n\u001b[1;32m     15\u001b[0m log_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m(log_string)\n",
      "File \u001b[0;32m~/Git/students/saba_ocedo/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BPIC15_1.xes'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "INPUT_FILES = [\"BPIC15_1.xes\", \"BPIC15_2.xes\", \"BPIC15_3.xes\", \"BPIC15_4.xes\", \"BPIC15_5.xes\"]  # List of input files\n",
    "CLASSIFIER = None  # Optional user-provided classifier\n",
    "\n",
    "def process_file(input_filename):\n",
    "    output_filename = input_filename.replace(\".xes\", \".json\")\n",
    "\n",
    "    # Read the file content and compute its hash\n",
    "    with open(input_filename) as f:\n",
    "        log_string = \"\".join(f.readlines())\n",
    "    log_hash = hash(log_string)\n",
    "    del log_string\n",
    "\n",
    "    events = []\n",
    "    objects = []\n",
    "    event_object = []\n",
    "    object_object = []\n",
    "\n",
    "    existing_objects = {}\n",
    "\n",
    "    tree = ET.parse(input_filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the first classifier\n",
    "    classifiers = root.findall('.//{http://www.xes-standard.org/}classifier')\n",
    "    if CLASSIFIER:\n",
    "        classifier = CLASSIFIER\n",
    "    elif classifiers:\n",
    "        classifier = classifiers[0].get('keys')\n",
    "    else:\n",
    "        classifier = \"concept:name lifecycle:transition\"\n",
    "    classifier = tuple(classifier.split(\" \"))\n",
    "\n",
    "    event_id_counter = 1\n",
    "    object_id_counter = 1\n",
    "    case_id_counter = 1\n",
    "\n",
    "    for case in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "        case_attributes = [child for child in case.iter() if child.tag != '{http://www.xes-standard.org/}event']\n",
    "        xes_case_id = None\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') == 'concept:name':\n",
    "                xes_case_id = attr.get('value')\n",
    "                break\n",
    "\n",
    "        case_id = f\"case_{case_id_counter}_{xes_case_id}_{log_hash}\" if xes_case_id else f\"case_{case_id_counter}_{log_hash}\"\n",
    "        case_id_counter += 1\n",
    "        case_id_hashed = f\"o_{hashlib.sha1(case_id.encode()).hexdigest()}\"\n",
    "        objects.append({\n",
    "            \"id\": case_id_hashed,\n",
    "            \"object_type\": \"case\",\n",
    "            \"attributes\": [{\"object_attribute_name\": \"concept:name\", \"object_attribute_value\": case_id}]\n",
    "        })\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') != 'concept:name':\n",
    "                object_type = attr.get('key')\n",
    "                object_value = attr.get('value')\n",
    "                object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "                \n",
    "                if object_key not in existing_objects:\n",
    "                    object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                    existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                    objects.append({\n",
    "                        \"id\": object_hash,\n",
    "                        \"object_type\": object_type,\n",
    "                        \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                    })\n",
    "                else:\n",
    "                    existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                object_object.append({\"from\": case_id_hashed, \"to\": object_id_hashed, \"object_relation_type\": \"case_object\"})\n",
    "\n",
    "        for event in [child for child in case.iter() if child.tag == '{http://www.xes-standard.org/}event']:\n",
    "            event_id = f\"event_{event_id_counter}_{log_hash}\"\n",
    "            event_id_counter += 1\n",
    "            event_id_hashed = f\"e_{hashlib.sha1(event_id.encode()).hexdigest()}\"\n",
    "            event_time_element = event.find('.//{http://www.xes-standard.org/}date')\n",
    "            event_time_iso8601 = None\n",
    "\n",
    "            if event_time_element is not None:\n",
    "                event_time = event_time_element.attrib.get('value')\n",
    "                if event_time:\n",
    "                    event_time_iso8601 = event_time.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "            event_classifier = OrderedDict.fromkeys(classifier)\n",
    "\n",
    "            event_attributes = [attr for attr in event.iter()]\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') in event_classifier:\n",
    "                    event_classifier[attr.get('key')] = attr.get('value')\n",
    "\n",
    "            event_type = \" \".join([v for v in event_classifier.values() if v is not None])\n",
    "\n",
    "            events.append({\n",
    "                \"id\": event_id_hashed,\n",
    "                \"time\": event_time_iso8601,\n",
    "                \"event_type\": event_type,\n",
    "                \"attributes\": [{\"event_attribute_name\": k, \"event_attribute_value\": v} for k, v in event_classifier.items() if v is not None]\n",
    "            })\n",
    "\n",
    "            event_object.append({\"eventID\": event_id_hashed, \"objectID\": case_id_hashed, \"qualifier\": \"case_event\"})\n",
    "\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') not in event_classifier and attr.get('key') != 'time:timestamp':\n",
    "                    object_type = attr.get('key')\n",
    "                    object_value = attr.get('value')\n",
    "                    object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "\n",
    "                    if object_key not in existing_objects:\n",
    "                        object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                        existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                        objects.append({\n",
    "                            \"id\": object_hash,\n",
    "                            \"object_type\": object_type,\n",
    "                            \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                        })\n",
    "                    else:\n",
    "                        existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                    object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                    event_object.append({\"eventID\": event_id_hashed, \"objectID\": object_id_hashed, \"qualifier\": \"event_object\"})\n",
    "\n",
    "    if len(object_object) < 1:\n",
    "        object_object.append({\"from\": \"\", \"to\": \"\", \"object_relation_type\": \"\"})\n",
    "\n",
    "    output_data = {\n",
    "        \"events\": events,\n",
    "        \"objects\": objects,\n",
    "        \"event_object\": event_object,\n",
    "        \"object_object\": object_object\n",
    "    }\n",
    "\n",
    "    with open(output_filename, 'w') as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "\n",
    "for input_file in INPUT_FILES:\n",
    "    process_file(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define input files\n",
    "INPUT_FILES = [\"BPIC15_1.xes\", \"BPIC15_2.xes\", \"BPIC15_3.xes\", \"BPIC15_4.xes\", \"BPIC15_5.xes\"]\n",
    "CLASSIFIER = None  # Optional user-provided classifier\n",
    "\n",
    "# Prefixes for TTL files\n",
    "PREFIXES = {\n",
    "    'ex': 'http://example.org/',\n",
    "}\n",
    "BASE_URI = PREFIXES['ex']\n",
    "\n",
    "def process_file(input_filename):\n",
    "    \"\"\"\n",
    "    Process an XES file to extract events, objects, and relations, and save them in JSON format.\n",
    "    \"\"\"\n",
    "    output_json_filename = input_filename.replace(\".xes\", \".json\")\n",
    "\n",
    "    # Read the file content and compute its hash\n",
    "    with open(input_filename) as f:\n",
    "        log_string = \"\".join(f.readlines())\n",
    "    log_hash = hash(log_string)\n",
    "    del log_string\n",
    "\n",
    "    events = []\n",
    "    objects = []\n",
    "    event_object = []\n",
    "    object_object = []\n",
    "\n",
    "    existing_objects = {}\n",
    "\n",
    "    tree = ET.parse(input_filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the first classifier\n",
    "    classifiers = root.findall('.//{http://www.xes-standard.org/}classifier')\n",
    "    if CLASSIFIER:\n",
    "        classifier = CLASSIFIER\n",
    "    elif classifiers:\n",
    "        classifier = classifiers[0].get('keys')\n",
    "    else:\n",
    "        classifier = \"concept:name lifecycle:transition\"\n",
    "    classifier = tuple(classifier.split(\" \"))\n",
    "\n",
    "    event_id_counter = 1\n",
    "    object_id_counter = 1\n",
    "    case_id_counter = 1\n",
    "\n",
    "    for case in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "        case_attributes = [child for child in case.iter() if child.tag != '{http://www.xes-standard.org/}event']\n",
    "        xes_case_id = None\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') == 'concept:name':\n",
    "                xes_case_id = attr.get('value')\n",
    "                break\n",
    "\n",
    "        case_id = f\"case_{case_id_counter}_{xes_case_id}_{log_hash}\" if xes_case_id else f\"case_{case_id_counter}_{log_hash}\"\n",
    "        case_id_counter += 1\n",
    "        case_id_hashed = f\"o_{hashlib.sha1(case_id.encode()).hexdigest()}\"\n",
    "        objects.append({\n",
    "            \"id\": case_id_hashed,\n",
    "            \"object_type\": \"case\",\n",
    "            \"attributes\": [{\"object_attribute_name\": \"concept:name\", \"object_attribute_value\": case_id}]\n",
    "        })\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') != 'concept:name':\n",
    "                object_type = attr.get('key')\n",
    "                object_value = attr.get('value')\n",
    "                object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "                \n",
    "                if object_key not in existing_objects:\n",
    "                    object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                    existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                    objects.append({\n",
    "                        \"id\": object_hash,\n",
    "                        \"object_type\": object_type,\n",
    "                        \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                    })\n",
    "                else:\n",
    "                    existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                object_object.append({\"from\": case_id_hashed, \"to\": object_id_hashed, \"object_relation_type\": \"case_object\"})\n",
    "\n",
    "        for event in [child for child in case.iter() if child.tag == '{http://www.xes-standard.org/}event']:\n",
    "            event_id = f\"event_{event_id_counter}_{log_hash}\"\n",
    "            event_id_counter += 1\n",
    "            event_id_hashed = f\"e_{hashlib.sha1(event_id.encode()).hexdigest()}\"\n",
    "            event_time_element = event.find('.//{http://www.xes-standard.org/}date')\n",
    "            event_time_iso8601 = None\n",
    "\n",
    "            if event_time_element is not None:\n",
    "                event_time = event_time_element.attrib.get('value')\n",
    "                if event_time:\n",
    "                    event_time_iso8601 = event_time.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "            event_classifier = OrderedDict.fromkeys(classifier)\n",
    "\n",
    "            event_attributes = [attr for attr in event.iter()]\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') in event_classifier:\n",
    "                    event_classifier[attr.get('key')] = attr.get('value')\n",
    "\n",
    "            event_type = \" \".join([v for v in event_classifier.values() if v is not None])\n",
    "\n",
    "            events.append({\n",
    "                \"id\": event_id_hashed,\n",
    "                \"time\": event_time_iso8601,\n",
    "                \"event_type\": event_type,\n",
    "                \"attributes\": [{\"event_attribute_name\": k, \"event_attribute_value\": v} for k, v in event_classifier.items() if v is not None]\n",
    "            })\n",
    "\n",
    "            event_object.append({\"eventID\": event_id_hashed, \"objectID\": case_id_hashed, \"qualifier\": \"case_event\"})\n",
    "\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') not in event_classifier and attr.get('key') != 'time:timestamp':\n",
    "                    object_type = attr.get('key')\n",
    "                    object_value = attr.get('value')\n",
    "                    object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "\n",
    "                    if object_key not in existing_objects:\n",
    "                        object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                        existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                        objects.append({\n",
    "                            \"id\": object_hash,\n",
    "                            \"object_type\": object_type,\n",
    "                            \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                        })\n",
    "                    else:\n",
    "                        existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                    object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                    event_object.append({\"eventID\": event_id_hashed, \"objectID\": object_id_hashed, \"qualifier\": \"event_object\"})\n",
    "\n",
    "    if len(object_object) < 1:\n",
    "        object_object.append({\"from\": \"\", \"to\": \"\", \"object_relation_type\": \"\"})\n",
    "\n",
    "    output_data = {\n",
    "        \"events\": events,\n",
    "        \"objects\": objects,\n",
    "        \"event_object\": event_object,\n",
    "        \"object_object\": object_object\n",
    "    }\n",
    "\n",
    "    with open(output_json_filename, 'w') as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"JSON Output saved to {output_json_filename}\")\n",
    "    \n",
    "    # Process TTL Relations\n",
    "    output_ttl_filename = input_filename.replace(\".xes\", \"_relation.ttl\")\n",
    "    create_ttl_relations(input_filename, output_ttl_filename)\n",
    "\n",
    "\n",
    "def create_ttl_relations(input_filename, output_filename):\n",
    "    \"\"\"\n",
    "    Create TTL relations from an XES file.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(input_filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    triples = set()\n",
    "    \n",
    "    for trace in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "        case_id = trace.attrib.get('concept:name', 'unknown_case_id')\n",
    "\n",
    "        trace_attrs = {}\n",
    "        event_attrs = {}\n",
    "\n",
    "        for attr in trace:\n",
    "            key = attr.attrib.get('key')\n",
    "            value = attr.attrib.get('value')\n",
    "            if key and value:\n",
    "                trace_attrs[key] = value\n",
    "\n",
    "        event_counter = 0\n",
    "        for event in trace.findall('./{http://www.xes-standard.org/}event'):\n",
    "            event_counter += 1\n",
    "            event_id = f\"event_{event_counter}\"\n",
    "            \n",
    "            event_attrs[event_id] = {}\n",
    "            \n",
    "            for attr in event:\n",
    "                key = attr.attrib.get('key')\n",
    "                value = attr.attrib.get('value')\n",
    "                if key and value:\n",
    "                    event_attrs[event_id][key] = value\n",
    "            \n",
    "            for trace_key, trace_value in trace_attrs.items():\n",
    "                subject = f'{BASE_URI}{trace_key}'\n",
    "                for event_key, event_value in event_attrs[event_id].items():\n",
    "                    object = f'{BASE_URI}{event_key}'\n",
    "                    triple = (subject, object)\n",
    "                    triples.add(triple)\n",
    "    \n",
    "    with open(output_filename, 'w') as f:\n",
    "        # Write prefix declaration\n",
    "        f.write('@prefix ex: <http://example.org/> .\\n\\n')\n",
    "        \n",
    "        for subject, object in triples:\n",
    "            relation = f'<{subject}> ex:subject_object <{object}> .'\n",
    "            f.write(f'{relation}\\n')\n",
    "    \n",
    "    print(f\"TTL Output saved to {output_filename}\")\n",
    "\n",
    "def extract_triples_from_ttl(filename):\n",
    "    \"\"\"\n",
    "    Extract triples from a TTL file.\n",
    "    \"\"\"\n",
    "    triples = set()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('<') and ' ex:subject_object ' in line:\n",
    "                triples.add(line.strip())\n",
    "    return triples\n",
    "\n",
    "def find_common_triples(output_filenames, common_output_filename):\n",
    "    \"\"\"\n",
    "    Find common triples among multiple TTL files and write them to a new file.\n",
    "    \"\"\"\n",
    "    if not output_filenames:\n",
    "        return\n",
    "    \n",
    "    common_triples = extract_triples_from_ttl(output_filenames[0])\n",
    "    \n",
    "    for filename in output_filenames[1:]:\n",
    "        current_triples = extract_triples_from_ttl(filename)\n",
    "        common_triples &= current_triples\n",
    "    \n",
    "    with open(common_output_filename, 'w') as f:\n",
    "        # Write prefix declaration\n",
    "        f.write('@prefix ex: <http://example.org/> .\\n\\n')\n",
    "        \n",
    "        # Sort the triples before writing\n",
    "        sorted_triples = sorted(common_triples)\n",
    "        \n",
    "        for triple in sorted_triples:\n",
    "            f.write(f'{triple}\\n')\n",
    "    \n",
    "    print(f\"Common triples saved to {common_output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filenames = [\"2015-1.xes\", \"2015-2.xes\", \"2015-3.xes\", \"2015-4.xes\", \"2015-5.xes\"]\n",
    "    output_filenames = [f\"{filename.split('.')[0]}_relation.ttl\" for filename in input_filenames]\n",
    "    common_output_filename = \"common_relationsBPIC15.ttl\"\n",
    "\n",
    "    if len(INPUT_FILES) != len(output_filenames):\n",
    "        raise ValueError(\"The number of input filenames must match the number of output filenames.\")\n",
    "    \n",
    "    for input_filename, output_filename in zip(INPUT_FILES, output_filenames):\n",
    "        if os.path.exists(input_filename):\n",
    "            process_file(input_filename)\n",
    "        else:\n",
    "            print(f\"File not found: {input_filename}\")\n",
    "\n",
    "    find_common_triples(output_filenames, common_output_filename)\n",
    "    #Merged outputs of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ed291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "INPUT_FILES = [\"bpic13/BPI2013_incidents.xes\"]  # List of input files\n",
    "CLASSIFIER = None  # Optional user-provided classifier\n",
    "\n",
    "def process_file(input_filename):\n",
    "    output_filename = input_filename.replace(\".xes\", \".json\")\n",
    "\n",
    "    # Read the file content and compute its hash\n",
    "    with open(input_filename) as f:\n",
    "        log_string = \"\".join(f.readlines())\n",
    "    log_hash = hash(log_string)\n",
    "    del log_string\n",
    "\n",
    "    events = []\n",
    "    objects = []\n",
    "    event_object = []\n",
    "    object_object = []\n",
    "\n",
    "    existing_objects = {}\n",
    "\n",
    "    tree = ET.parse(input_filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the first classifier\n",
    "    classifiers = root.findall('.//{http://www.xes-standard.org/}classifier')\n",
    "    if CLASSIFIER:\n",
    "        classifier = CLASSIFIER\n",
    "    elif classifiers:\n",
    "        classifier = classifiers[0].get('keys')\n",
    "    else:\n",
    "        classifier = \"concept:name lifecycle:transition\"\n",
    "    classifier = tuple(classifier.split(\" \"))\n",
    "\n",
    "    event_id_counter = 1\n",
    "    object_id_counter = 1\n",
    "    case_id_counter = 1\n",
    "\n",
    "    for case in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "        case_attributes = [child for child in case.iter() if child.tag != '{http://www.xes-standard.org/}event']\n",
    "        xes_case_id = None\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') == 'concept:name':\n",
    "                xes_case_id = attr.get('value')\n",
    "                break\n",
    "\n",
    "        case_id = f\"case_{case_id_counter}_{xes_case_id}_{log_hash}\" if xes_case_id else f\"case_{case_id_counter}_{log_hash}\"\n",
    "        case_id_counter += 1\n",
    "        case_id_hashed = f\"o_{hashlib.sha1(case_id.encode()).hexdigest()}\"\n",
    "        objects.append({\n",
    "            \"id\": case_id_hashed,\n",
    "            \"object_type\": \"case\",\n",
    "            \"attributes\": [{\"object_attribute_name\": \"concept:name\", \"object_attribute_value\": case_id}]\n",
    "        })\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') != 'concept:name':\n",
    "                object_type = attr.get('key')\n",
    "                object_value = attr.get('value')\n",
    "                object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "                \n",
    "                if object_key not in existing_objects:\n",
    "                    object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                    existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                    objects.append({\n",
    "                        \"id\": object_hash,\n",
    "                        \"object_type\": object_type,\n",
    "                        \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                    })\n",
    "                else:\n",
    "                    existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                object_object.append({\"from\": case_id_hashed, \"to\": object_id_hashed, \"object_relation_type\": \"case_object\"})\n",
    "\n",
    "        for event in [child for child in case.iter() if child.tag == '{http://www.xes-standard.org/}event']:\n",
    "            event_id = f\"event_{event_id_counter}_{log_hash}\"\n",
    "            event_id_counter += 1\n",
    "            event_id_hashed = f\"e_{hashlib.sha1(event_id.encode()).hexdigest()}\"\n",
    "            event_time_element = event.find('.//{http://www.xes-standard.org/}date')\n",
    "            event_time_iso8601 = None\n",
    "\n",
    "            if event_time_element is not None:\n",
    "                event_time = event_time_element.attrib.get('value')\n",
    "                if event_time:\n",
    "                    event_time_iso8601 = event_time.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "            event_classifier = OrderedDict.fromkeys(classifier)\n",
    "\n",
    "            event_attributes = [attr for attr in event.iter()]\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') in event_classifier:\n",
    "                    event_classifier[attr.get('key')] = attr.get('value')\n",
    "\n",
    "            event_type = \" \".join([v for v in event_classifier.values() if v is not None])\n",
    "\n",
    "            events.append({\n",
    "                \"id\": event_id_hashed,\n",
    "                \"time\": event_time_iso8601,\n",
    "                \"event_type\": event_type,\n",
    "                \"attributes\": [{\"event_attribute_name\": k, \"event_attribute_value\": v} for k, v in event_classifier.items() if v is not None]\n",
    "            })\n",
    "\n",
    "            event_object.append({\"eventID\": event_id_hashed, \"objectID\": case_id_hashed, \"qualifier\": \"case_event\"})\n",
    "\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') not in event_classifier and attr.get('key') != 'time:timestamp':\n",
    "                    object_type = attr.get('key')\n",
    "                    object_value = attr.get('value')\n",
    "                    object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "\n",
    "                    if object_key not in existing_objects:\n",
    "                        object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                        existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                        objects.append({\n",
    "                            \"id\": object_hash,\n",
    "                            \"object_type\": object_type,\n",
    "                            \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                        })\n",
    "                    else:\n",
    "                        existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                    object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                    event_object.append({\"eventID\": event_id_hashed, \"objectID\": object_id_hashed, \"qualifier\": \"event_object\"})\n",
    "\n",
    "    if len(object_object) < 1:\n",
    "        object_object.append({\"from\": \"\", \"to\": \"\", \"object_relation_type\": \"\"})\n",
    "\n",
    "    output_data = {\n",
    "        \"events\": events,\n",
    "        \"objects\": objects,\n",
    "        \"event_object\": event_object,\n",
    "        \"object_object\": object_object\n",
    "    }\n",
    "\n",
    "    with open(output_filename, 'w') as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "\n",
    "for input_file in INPUT_FILES:\n",
    "    process_file(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "INPUT_FILES = [\"bpic13/13small.xes\"]  # List of input files\n",
    "CLASSIFIER = None  # Optional user-provided classifier\n",
    "\n",
    "def process_file(input_filename):\n",
    "    output_filename = input_filename.replace(\".xes\", \".json\")\n",
    "\n",
    "    # Read the file content and compute its hash\n",
    "    with open(input_filename) as f:\n",
    "        log_string = \"\".join(f.readlines())\n",
    "    log_hash = hash(log_string)\n",
    "    del log_string\n",
    "\n",
    "    events = []\n",
    "    objects = []\n",
    "    event_object = []\n",
    "    object_object = []\n",
    "\n",
    "    existing_objects = {}\n",
    "\n",
    "    tree = ET.parse(input_filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the first classifier\n",
    "    classifiers = root.findall('.//{http://www.xes-standard.org/}classifier')\n",
    "    if CLASSIFIER:\n",
    "        classifier = CLASSIFIER\n",
    "    elif classifiers:\n",
    "        classifier = classifiers[0].get('keys')\n",
    "    else:\n",
    "        classifier = \"concept:name lifecycle:transition\"\n",
    "    classifier = tuple(classifier.split(\" \"))\n",
    "\n",
    "    event_id_counter = 1\n",
    "    object_id_counter = 1\n",
    "    case_id_counter = 1\n",
    "\n",
    "    for case in root.findall('.//{http://www.xes-standard.org/}trace'):\n",
    "        case_attributes = [child for child in case.iter() if child.tag != '{http://www.xes-standard.org/}event']\n",
    "        xes_case_id = None\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') == 'concept:name':\n",
    "                xes_case_id = attr.get('value')\n",
    "                break\n",
    "\n",
    "        case_id = f\"case_{case_id_counter}_{xes_case_id}_{log_hash}\" if xes_case_id else f\"case_{case_id_counter}_{log_hash}\"\n",
    "        case_id_counter += 1\n",
    "        case_id_hashed = f\"o_{hashlib.sha1(case_id.encode()).hexdigest()}\"\n",
    "        objects.append({\n",
    "            \"id\": case_id_hashed,\n",
    "            \"object_type\": \"case\",\n",
    "            \"attributes\": [{\"object_attribute_name\": \"concept:name\", \"object_attribute_value\": case_id}]\n",
    "        })\n",
    "\n",
    "        for attr in case_attributes:\n",
    "            if attr.get('key') != 'concept:name':\n",
    "                object_type = attr.get('key')\n",
    "                object_value = attr.get('value')\n",
    "                object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "                \n",
    "                if object_key not in existing_objects:\n",
    "                    object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                    existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                    objects.append({\n",
    "                        \"id\": object_hash,\n",
    "                        \"object_type\": object_type,\n",
    "                        \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                    })\n",
    "                else:\n",
    "                    existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                object_object.append({\"from\": case_id_hashed, \"to\": object_id_hashed, \"object_relation_type\": \"case_object\"})\n",
    "\n",
    "        for event in [child for child in case.iter() if child.tag == '{http://www.xes-standard.org/}event']:\n",
    "            event_id = f\"event_{event_id_counter}_{log_hash}\"\n",
    "            event_id_counter += 1\n",
    "            event_id_hashed = f\"e_{hashlib.sha1(event_id.encode()).hexdigest()}\"\n",
    "            event_time_element = event.find('.//{http://www.xes-standard.org/}date')\n",
    "            event_time_iso8601 = None\n",
    "\n",
    "            if event_time_element is not None:\n",
    "                event_time = event_time_element.attrib.get('value')\n",
    "                if event_time:\n",
    "                    event_time_iso8601 = event_time.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "\n",
    "            event_classifier = OrderedDict.fromkeys(classifier)\n",
    "\n",
    "            event_attributes = [attr for attr in event.iter()]\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') in event_classifier:\n",
    "                    event_classifier[attr.get('key')] = attr.get('value')\n",
    "\n",
    "            event_type = \" \".join([v for v in event_classifier.values() if v is not None])\n",
    "\n",
    "            events.append({\n",
    "                \"id\": event_id_hashed,\n",
    "                \"time\": event_time_iso8601,\n",
    "                \"event_type\": event_type,\n",
    "                \"attributes\": [{\"event_attribute_name\": k, \"event_attribute_value\": v} for k, v in event_classifier.items() if v is not None]\n",
    "            })\n",
    "\n",
    "            event_object.append({\"eventID\": event_id_hashed, \"objectID\": case_id_hashed, \"qualifier\": \"case_event\"})\n",
    "\n",
    "            for attr in event_attributes:\n",
    "                if attr.get('key') not in event_classifier and attr.get('key') != 'time:timestamp':\n",
    "                    object_type = attr.get('key')\n",
    "                    object_value = attr.get('value')\n",
    "                    object_key = f\"{object_type}_{object_value}_{log_hash}\"\n",
    "\n",
    "                    if object_key not in existing_objects:\n",
    "                        object_hash = f\"o_{hashlib.sha1(object_key.encode()).hexdigest()}\"\n",
    "                        existing_objects[object_key] = {\"id\": object_hash, \"count\": 1}\n",
    "                        objects.append({\n",
    "                            \"id\": object_hash,\n",
    "                            \"object_type\": object_type,\n",
    "                            \"attributes\": [{\"object_attribute_name\": object_type, \"object_attribute_value\": object_value}]\n",
    "                        })\n",
    "                    else:\n",
    "                        existing_objects[object_key][\"count\"] += 1\n",
    "\n",
    "                    object_id_hashed = existing_objects[object_key][\"id\"]\n",
    "                    event_object.append({\"eventID\": event_id_hashed, \"objectID\": object_id_hashed, \"qualifier\": \"event_object\"})\n",
    "\n",
    "    if len(object_object) < 1:\n",
    "        object_object.append({\"from\": \"\", \"to\": \"\", \"object_relation_type\": \"\"})\n",
    "\n",
    "    output_data = {\n",
    "        \"events\": events,\n",
    "        \"objects\": objects,\n",
    "        \"event_object\": event_object,\n",
    "        \"object_object\": object_object\n",
    "    }\n",
    "\n",
    "    with open(output_filename, 'w') as json_file:\n",
    "        json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "\n",
    "for input_file in INPUT_FILES:\n",
    "    process_file(input_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
